{
  "comments": [
    {
      "key": {
        "uuid": "8f14d6b3_77ea98bb",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 509,
      "author": {
        "id": 1366072
      },
      "writtenOn": "2019-10-29T08:28:16Z",
      "side": 1,
      "message": "Add comments why it needs caching here.",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6f43b2b8_3f92f2fe",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 509,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-30T07:32:00Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "8f14d6b3_77ea98bb",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "d7fcc035_723b5ef6",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1366072
      },
      "writtenOn": "2019-10-29T08:28:16Z",
      "side": 1,
      "message": "Is there a way to enforce \"unique constraint\" to Datastore?\nUsing memcache for \"lock\" may end up with unexpected cache inconsistent issues.",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "f72d6f0d_ff5676d2",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1366072
      },
      "writtenOn": "2019-10-29T08:35:41Z",
      "side": 1,
      "message": "Shouldn\u0027t all requests have request_uuid? How are you going to generate request_uuid?",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "be148157_9e84bef0",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-29T08:39:47Z",
      "side": 1,
      "message": "We need to change client side too for this. And making this field mandatry sounds good idea if it is done eventually.",
      "parentUuid": "f72d6f0d_ff5676d2",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "0cca1fa7_43ee61ca",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-29T08:39:47Z",
      "side": 1,
      "message": "\u003e Is there a way to enforce \"unique constraint\" to Datastore?\n\nI don\u0027t think so, we need to handle such constraint in application layer if necessary.\n\n\u003e Using memcache for \"lock\" may end up with unexpected cache inconsistent issues.\n\nWhat do you mean \"lock\"?",
      "parentUuid": "d7fcc035_723b5ef6",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "aaf3bb42_5849b305",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1366072
      },
      "writtenOn": "2019-10-29T08:51:23Z",
      "side": 1,
      "message": "Please correct me if I\u0027m wrong. If the IDs are about requests, you can generate them on server sides. Or is it about requester IDs?",
      "parentUuid": "be148157_9e84bef0",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "03a0a673_276f25ba",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-29T09:03:51Z",
      "side": 1,
      "message": "request_uuid is id that client generates for a single request.\n\nThis will be used for the case when client does retry after they see some failure response from swarming server.",
      "parentUuid": "aaf3bb42_5849b305",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "438e5c9b_3b19a0a5",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1366072
      },
      "writtenOn": "2019-10-29T09:04:24Z",
      "side": 1,
      "message": "Let\u0027t say the server received two same requests from a bot at the very same time.\nAnd after one created a request record but before creating a cache (around line 528), the second one could create a duplicated request because it doesn\u0027t find any caches.\nThat\u0027s the risk of the current implementation.\n\nIn typical relational DB like MySQL PostgreSQL, you can use unique constraint to avoid duplication. But I\u0027m not sure how to do it in NoSQL like Datastore.",
      "parentUuid": "0cca1fa7_43ee61ca",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "45437578_caa716cc",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-29T09:22:41Z",
      "side": 1,
      "message": "If we want to avoid such task duplication, we need to do db access in schedule_request as a transaction with check of request_uuid. But that may increase latency of task create request badly.\n\nI hope we don\u0027t need to guarantee such level of idempotency now.",
      "parentUuid": "438e5c9b_3b19a0a5",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "055234c9_5d3a1d4d",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1000487
      },
      "writtenOn": "2019-10-29T13:02:19Z",
      "side": 1,
      "message": "It is possible:\n\nFirst, create a new root entity type TaskRequest:\n\nclass TaskRequest(ndb.Model):\n  \"\"\"Entity id is the request_uuid.\"\"\"\n  task_id \u003d ndb.StringProperty(indexed\u003dFalse)\n\nSecond, use TaskRequest.get_or_insert() to detect if the entity existed before.\n\nThat\u0027s still one more transaction in the hot path, so it\u0027s slow, but it\u0027s upgrading from \"best effort\" to \"consistent\".\nSee https://cloud.google.com/appengine/docs/standard/python/ndb/modelclass#Model_get_or_insert\n\nThat said, this function *does* use memcache under the hood, so ironically it\u0027d be faster in the retry path. :)",
      "parentUuid": "45437578_caa716cc",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "23a48c05_154a149b",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1366072
      },
      "writtenOn": "2019-10-30T05:47:16Z",
      "side": 1,
      "message": "Ack",
      "parentUuid": "03a0a673_276f25ba",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "6533613f_0b918027",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1366072
      },
      "writtenOn": "2019-10-30T05:47:16Z",
      "side": 1,
      "message": "I understand this is a design choice. should leave the comment after finishing the implementation.\n\n\u003e get_or_insert\n\nget_or_insert sounds good to me. but not sure how much cost it will be adding.\nBut assuming that there are not many duplicated task new requests, it won\u0027t be able to take advantage from it.\n\n---\nAnother idea (complicated, though)\npessimistic lock using memcache, but no extra DB read.\n\n\nlock \u003d memcache.get(uuid, namespace\u003d\u0027task_new_lock\u0027)\nwhile lock:\n  cache \u003d memcache.get(uuid, namespace\u003d\u0027task_new\u0027)\n  if cache:\n    # validate and return the cache\n  # wait\n\n# add lock\nmemcache.add(uuid, namespace\u003d\u0027task_new_lock\u0027)\n\n# if the process can get lock, it will proceed task creation\ntask_summary \u003d task_scheduler.schedule_request(...)\nrequest_metadata \u003d ...\n\n# save task_summary to memcache and remove lock\nmemcache.add(uuid, request_metadata, namespace\u003d\u0027task_new\u0027) \nmemcache.delete(uuid, namespace\u003d\u0027task_new_lock\u0027)\n\n\nyou could fail the request if the lock exists instead of waiting for the complete.",
      "parentUuid": "055234c9_5d3a1d4d",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "171a4184_dac45b98",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-30T07:32:00Z",
      "side": 1,
      "message": "Hmm, I want to try best effort implementation first until we found that is not enough.\nIt is bit simpler and hopefully faster.",
      "parentUuid": "6533613f_0b918027",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c441e0fd_061eaef0",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1000487
      },
      "writtenOn": "2019-10-30T13:26:52Z",
      "side": 1,
      "message": "I think starting with best effort first and falling back to fully coherent after (without any API change) is the best way to do this.",
      "parentUuid": "171a4184_dac45b98",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "c106c508_4ac21121",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 510,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-30T14:01:32Z",
      "side": 1,
      "message": "Let me leave TODO. After moving the logic to task_scheduler.py, it will be done bit easier.",
      "parentUuid": "c441e0fd_061eaef0",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "25ccf05c_4bf611f4",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 511,
      "author": {
        "id": 1000487
      },
      "writtenOn": "2019-10-29T13:02:19Z",
      "side": 1,
      "message": "Please validate that the UUID is in the form of a UUID.",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "e4546b79_b9011378",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 511,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-30T07:32:00Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "25ccf05c_4bf611f4",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "fbd906bd_6f5aa2db",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 513,
      "author": {
        "id": 1366072
      },
      "writtenOn": "2019-10-29T08:28:16Z",
      "side": 1,
      "message": "Log something useful? like the request xxx has already been created... etc",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "52851358_c73231ed",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 513,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-30T07:32:00Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "fbd906bd_6f5aa2db",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ad58a8ba_be1fae33",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 514,
      "author": {
        "id": 1000487
      },
      "writtenOn": "2019-10-29T13:02:19Z",
      "side": 1,
      "message": "When a retry is detected, you need to assert that it is exactly the same request. If not, you need to deny the request with a 400.",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "1dfd40c2_28d0d81f",
        "filename": "appengine/swarming/handlers_endpoints.py",
        "patchSetId": 3
      },
      "lineNbr": 514,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-30T07:32:00Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "ad58a8ba_be1fae33",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3aa30d4c_a85bf6e4",
        "filename": "appengine/swarming/proto/api/swarming.proto",
        "patchSetId": 3
      },
      "lineNbr": 828,
      "author": {
        "id": 1000487
      },
      "writtenOn": "2019-10-29T13:02:19Z",
      "side": 1,
      "message": "In cloud endpoints, you added it to NewTaskRequest but not to TaskRequest. I\u0027d recommend the same here. Since NewTaskRequest doesn\u0027t yet exist in the proto form, then you should simply remove this form. :)\n\nOn the other hand, if you see value in permitting the user to retrieve this back or to put this in BQ it\u0027s fine with me, but I think it\u0027s not worth it for now.",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "1b78509e_182f6788",
        "filename": "appengine/swarming/proto/api/swarming.proto",
        "patchSetId": 3
      },
      "lineNbr": 828,
      "author": {
        "id": 1161379
      },
      "writtenOn": "2019-10-30T07:32:00Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "3aa30d4c_a85bf6e4",
      "revId": "1ba5ff08635457cc625e9000c38aa36a36f70e2b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}