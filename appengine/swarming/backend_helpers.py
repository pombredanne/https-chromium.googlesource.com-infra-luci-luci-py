# Copyright 2021 The LUCI Authors. All rights reserved.
# Use of this source code is governed under the Apache License, Version 2.0
# that can be found in the LICENSE file.
"""
"""

from server import config

# This is the path, relative to the swarming run dir, to the directory that
# contains the mounted swarming named caches. It will be prepended to paths of
# caches defined in swarmbucket configs.
_CACHE_DIR = 'cache'


def _ingest_run_task_request(run_task_req):
  # type: (taskbackend_service_pb2.RunTaskRequest) -> task_request.TaskRequest

  return task_request.TaskRequest(
      created_ts=utils.utcnow(),
      task_slices = _compute_task_slices(run_task_req),
      expiration_ts = run_task_req.start_dealine.seconds,
      name = 'bb-%d-???' % (run_task_request.build_id), # TODO: need builder_id?
      authenticated = '', # Authenticated client that triggered this task.
      # Which user to blame for this task. Can be arbitrary, not asserted by any
      # credentials.
      user = '',
      # Indicates what OAuth2 credentials the task uses when calling other services.
      # Possible values are: 'none', 'bot' or <email>. For more information see
      # swarming_rpcs.NewTaskRequest.
      service_account = '',
      # The "OAuth token grant" generated when the task was posted.
      # This is an opaque token generated by the Token Server at the time the task
      # was posted (when the end-user is still present). It can be exchanged
      # for an OAuth token of some service account at a later time (when the task is
      # actually running on some bot).
      # Set only for tasks that used legacy (non-realm) ACLs when checking if
      # a task can use the requested service account.
      # This property never shows up in UI or API responses.
      service_account_token = ndb.BlobProperty(),
      priority = run_task_req.backend_config.priority,
      tags = '', # backend_config? or moved to bbagent? check _compute_tags
      manual_tags = '', # not used?
      parent_task_id = run_task_req.backend_config.parent_run_id,
      pubsub_topic = 'projects/%s/topics/swarming', # TODO usually bb application_id
      pubsub_userdata = '', # TODO
      pubsub_auth_token = '', # TODO
      bot_ping_tolerance_secs = '', # TODO
      resultdb_update_token = '', # TODO
      realm = '',
      realm_enabled = '',
      resultdb = '',
      )


def _compute_task_slices(run_task_req):
  # type: (taskbackend_service_pb2.RunTaskRequest) -> Sequence[task_request.TaskSlice]

  # {expiration_secs: {'key': [value1, ...], 'key2': [value1, ...]}
  dims_by_exp = collections.defaultdict(lambda: defaultdict(int))

  for cache in run_task_req.caches:
    assert not cache.wait_for_warm_caches.nanos
    if cache.wait_for_warm_caches.seconds:
      dims_by_exp[cache.wait_for_warm_caches.seconds]['caches'].append(cache.name)

  for dim in run_task_req.dimensions:
    assert not dim.expiration.nans
    dims_by_exp[dim.expiration.seconds][dim.key].append(dim.value)

  base_dims = dims_by_exp.pop(0, {})
  for key, values in base_dims.iteritems():
    #dims_sort_key = lambda x: (x['key'], x['value'])
    values.sort()

  base_slice = task_request.TaskSlice(
      HASHING_ALGO = '',
      wait_for_capacity = run_task_req.backend_config.wait_for_capacity,
      properties = task_request.TaskProperties(
          caches = [
              task_request.CacheEntry(
                  path=posixpath.join(_CACHE_DIR, cache.path), name=cache.name)
              for cache in run_task_req.caches],
          command = _compute_command(run_task_req),
          relative_cwd = '',
          cas_input_root = task_request.CASReference(),
          cipd_input = task_request.CipdInput(),
          dimensions_data = base_dims,
          env = {},
          env_prefixes = _compute_env_prefixes(run_task_req.caches),
          execution_timeout_secs = run_task_req.execution_timeout.seconds,
          grace_preiod_secs = run_task_req.grace_period.seconds,
          io_timeout_secs = 1, # TODO
          idempotent = True, # TODO
          outputs = '', # TODO
          has_secret_bytes = '', # TODO
          containment = task_request.Containment(
              containment_type=_ingest_containment_type(run_task_req.backend_config.containment.containment_type),
              lower_priority=run_task_req.backend_config.containment.lower_priority,
              limit_processes=run_task_req.backend_config.containment.limit_processes,
              limit_total_committed_memory = run_task_req.backend_config.containment.limit_total_committed_memory
          ),
      ),
  )

  if not dims_by_exp:
    return [base_slice]

  assert len(dims_by_exp) <= 6, 'too many task slices: %v' % dims_by_exp

  # Initialize task slices with base properties and computed expiration.
  last_exp = 0
  task_slices = []
  for expiration_secs in sorted(dims_by_exp):
    task_slices.append(
        task_request.TaskSlice(
            expiration_secs = expiration_secs - last_exp,
            properties = copy.deepcopy(base_slice.properties),
        ))
    last_exp = expiration_secs

  # Add extra dimensions for all slices.
  extra_dims = defaultdict(list)
  for i, (_expiration,
          dims) in enumerate(sorted(dims_by_exp.iteritems(), reverse=True)):
    props = task_slices[-1 - i].properties
    for key, values in dims.iteritems():
      extra_dims[key].extend(values)
      props.dimensions.setdefault(key, []).extend(extra_dims[key])
      props.dimensions[key].sort()

  # Adjust expiration on base_slice and add it as the last slice.
  base_exp = run_task_req.start_deadline - utils.utcnow()
  base_slice['expiration_secs'] = max(base_exp - last_exp, 60)
  task_slices.append(base_slice)

  return task_slices


def _ingest_containment_type():
  pass

def _compute_command(run_task_request):
  pass


def _compute_env_prefixes(request_caches):
  # type: (NamedCahces) -> Sequence[Mapping]
  """Returns list of env_prefixes key values."""
  # TODO: will bbagent handle adding user_package directories to PATH?
  env_prefixes = collectsion.default_dict(list)
  for cache in request_caches:
    if cache.env_var:
      env_prefixes[env_var].append(posixpath.join(_CACHE_DIR, cache.path))


def _call_swarming_api_async(
    path,
    method='GET',
    payload=None,
    act_as_project=None,
    impersonate=False,
    delegation_tag=None,
    delegation_identitiy=None,
    deadline=None,
    max_attempts=None,
):

  yield net.json_request_async(
      url='/_ah/api/swarming/v1/%s' % path,
      method=method,
      payload=payload,
      scopes=net.EMAIL_SCOPE,
      project_id=act_as_project)
